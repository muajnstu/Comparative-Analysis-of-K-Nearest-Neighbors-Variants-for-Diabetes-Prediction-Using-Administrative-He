{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muajnstu/DSK-Chain-to-predict-diabeties-/blob/main/Exploring_Voting_%26_Stacking_KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "x6ZbcE4l_qJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(y_true, y_pred, y_prob=None):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    num_classes = cm.shape[0]\n",
        "\n",
        "    if num_classes == 2:\n",
        "        # Binary classification\n",
        "        TN, FP, FN, TP = cm.ravel()\n",
        "        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        gmean = np.sqrt(specificity * sensitivity)\n",
        "        type1 = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
        "        type2 = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        fmeasure = f1_score(y_true, y_pred, pos_label=1)\n",
        "        auc = 0\n",
        "        if y_prob is not None and hasattr(y_prob, \"shape\") and y_prob.shape[1] > 1:\n",
        "            try:\n",
        "                auc = roc_auc_score(y_true, y_prob[:, 1])\n",
        "            except Exception:\n",
        "                auc = 0\n",
        "\n",
        "    else:\n",
        "        # Multiclass classification\n",
        "        TP = np.diag(cm)\n",
        "        FP = np.sum(cm, axis=0) - TP\n",
        "        FN = np.sum(cm, axis=1) - TP\n",
        "        TN = np.sum(cm) - (FP + FN + TP)\n",
        "\n",
        "        specificity = np.mean([\n",
        "            TN[i] / (TN[i] + FP[i]) if (TN[i] + FP[i]) > 0 else 0 for i in range(num_classes)\n",
        "        ])\n",
        "        sensitivity = np.mean([\n",
        "            TP[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0 for i in range(num_classes)\n",
        "        ])\n",
        "        gmean = np.sqrt(specificity * sensitivity)\n",
        "        type1 = np.mean([\n",
        "            FP[i] / (FP[i] + TN[i]) if (FP[i] + TN[i]) > 0 else 0 for i in range(num_classes)\n",
        "        ])\n",
        "        type2 = np.mean([\n",
        "            FN[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0 for i in range(num_classes)\n",
        "        ])\n",
        "        fmeasure = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "        auc = 0\n",
        "        if y_prob is not None and hasattr(y_prob, \"shape\") and y_prob.shape[1] > 1:\n",
        "            try:\n",
        "                auc = roc_auc_score(y_true, y_prob, multi_class='ovr', average='macro')\n",
        "            except Exception:\n",
        "                auc = 0\n",
        "\n",
        "    # Print or return results\n",
        "    print(f\"Accuracy      : {accuracy:.4f}\")\n",
        "    print(f\"Sensitivity   : {sensitivity:.4f}\")\n",
        "    print(f\"Specificity   : {specificity:.4f}\")\n",
        "    print(f\"G-Mean        : {gmean:.4f}\")\n",
        "    print(f\"Type I Error  : {type1:.4f}\")\n",
        "    print(f\"Type II Error : {type2:.4f}\")\n",
        "    print(f\"F1 Score      : {fmeasure:.4f}\")\n",
        "    print(f\"AUROC         : {auc:.4f}\")\n",
        "\n",
        "def run_knn_variant(name, knn_clf):\n",
        "    print(f\"\\n==== {name} ====\")\n",
        "    knn_clf.fit(X_train, y_train)\n",
        "    y_pred = knn_clf.predict(X_test)\n",
        "    if hasattr(knn_clf, \"predict_proba\"):\n",
        "        try:\n",
        "            y_prob = knn_clf.predict_proba(X_test)\n",
        "        except Exception:\n",
        "            y_prob = None\n",
        "    else:\n",
        "        y_prob = None\n",
        "    print_metrics(y_test, y_pred, y_prob)"
      ],
      "metadata": {
        "id": "nYljXbvj_vCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/muajnstu/ML-Datasets/refs/heads/main/filtered_df.csv')\n",
        "X = df.drop(columns=['Cluster'])\n",
        "y = df['Cluster']\n",
        "\n",
        "# Handle Imbalanced Data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=46, stratify=y_resampled\n",
        ")"
      ],
      "metadata": {
        "id": "PWerarA__5wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g23As_2O3hRB",
        "outputId": "d65a669e-b9f0-4ef5-dded-37051b09022b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== KNN ====\n",
            "Accuracy      : 0.9217\n",
            "Sensitivity   : 0.9217\n",
            "Specificity   : 0.9608\n",
            "G-Mean        : 0.9411\n",
            "Type I Error  : 0.0392\n",
            "Type II Error : 0.0783\n",
            "F1 Score      : 0.9205\n",
            "AUROC         : 0.9648\n",
            "\n",
            "==== DistanceKNN ====\n",
            "Accuracy      : 0.9276\n",
            "Sensitivity   : 0.9276\n",
            "Specificity   : 0.9638\n",
            "G-Mean        : 0.9455\n",
            "Type I Error  : 0.0362\n",
            "Type II Error : 0.0724\n",
            "F1 Score      : 0.9264\n",
            "AUROC         : 0.9667\n",
            "\n",
            "==== GeneralizedKNN ====\n",
            "Accuracy      : 0.9268\n",
            "Sensitivity   : 0.9268\n",
            "Specificity   : 0.9634\n",
            "G-Mean        : 0.9449\n",
            "Type I Error  : 0.0366\n",
            "Type II Error : 0.0732\n",
            "F1 Score      : 0.9260\n",
            "AUROC         : 0.9673\n",
            "\n",
            "==== EuclideanKNN ====\n",
            "Accuracy      : 0.9217\n",
            "Sensitivity   : 0.9217\n",
            "Specificity   : 0.9608\n",
            "G-Mean        : 0.9411\n",
            "Type I Error  : 0.0392\n",
            "Type II Error : 0.0783\n",
            "F1 Score      : 0.9205\n",
            "AUROC         : 0.9648\n",
            "\n",
            "==== ManhattanKNN ====\n",
            "Accuracy      : 0.8881\n",
            "Sensitivity   : 0.8881\n",
            "Specificity   : 0.9440\n",
            "G-Mean        : 0.9156\n",
            "Type I Error  : 0.0560\n",
            "Type II Error : 0.1119\n",
            "F1 Score      : 0.8843\n",
            "AUROC         : 0.9506\n",
            "\n",
            "==== ChebyshevKNN ====\n",
            "Accuracy      : 0.8845\n",
            "Sensitivity   : 0.8845\n",
            "Specificity   : 0.9423\n",
            "G-Mean        : 0.9129\n",
            "Type I Error  : 0.0577\n",
            "Type II Error : 0.1155\n",
            "F1 Score      : 0.8853\n",
            "AUROC         : 0.9548\n",
            "\n",
            "==== MahalanobisKNN ====\n",
            "Accuracy      : 0.9620\n",
            "Sensitivity   : 0.9620\n",
            "Specificity   : 0.9810\n",
            "G-Mean        : 0.9715\n",
            "Type I Error  : 0.0190\n",
            "Type II Error : 0.0380\n",
            "F1 Score      : 0.9614\n",
            "AUROC         : 0.9812\n",
            "\n",
            "==== SeuclideanKNN ====\n",
            "Accuracy      : 0.9537\n",
            "Sensitivity   : 0.9537\n",
            "Specificity   : 0.9769\n",
            "G-Mean        : 0.9652\n",
            "Type I Error  : 0.0231\n",
            "Type II Error : 0.0463\n",
            "F1 Score      : 0.9528\n",
            "AUROC         : 0.9791\n",
            "\n",
            "==== WminkowskiKNN ====\n",
            "Accuracy      : 0.9268\n",
            "Sensitivity   : 0.9268\n",
            "Specificity   : 0.9634\n",
            "G-Mean        : 0.9449\n",
            "Type I Error  : 0.0366\n",
            "Type II Error : 0.0732\n",
            "F1 Score      : 0.9260\n",
            "AUROC         : 0.9673\n",
            "\n",
            "==== Voting Ensemble ====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: SyntaxWarning: Parameter p is found in metric_params. The corresponding parameter from __init__ is ignored.\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy      : 0.9351\n",
            "Sensitivity   : 0.9351\n",
            "Specificity   : 0.9676\n",
            "G-Mean        : 0.9512\n",
            "Type I Error  : 0.0324\n",
            "Type II Error : 0.0649\n",
            "F1 Score      : 0.9339\n",
            "AUROC         : 0.9906\n",
            "\n",
            "==== Stacking Ensemble ====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: SyntaxWarning: Parameter p is found in metric_params. The corresponding parameter from __init__ is ignored.\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: SyntaxWarning: Parameter p is found in metric_params. The corresponding parameter from __init__ is ignored.\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: SyntaxWarning: Parameter p is found in metric_params. The corresponding parameter from __init__ is ignored.\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: SyntaxWarning: Parameter p is found in metric_params. The corresponding parameter from __init__ is ignored.\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: SyntaxWarning: Parameter p is found in metric_params. The corresponding parameter from __init__ is ignored.\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: SyntaxWarning: Parameter p is found in metric_params. The corresponding parameter from __init__ is ignored.\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy      : 0.9703\n",
            "Sensitivity   : 0.9703\n",
            "Specificity   : 0.9852\n",
            "G-Mean        : 0.9777\n",
            "Type I Error  : 0.0148\n",
            "Type II Error : 0.0297\n",
            "F1 Score      : 0.9702\n",
            "AUROC         : 0.9874\n",
            "\n",
            "Project complete! Check the above output for performance of each KNN variant and ensemble models.\n"
          ]
        }
      ],
      "source": [
        "# Recalculate covariance and variance with the current X_train after SMOTE\n",
        "covariance_matrix = np.cov(X_train.T)\n",
        "stabilized_covariance_matrix = covariance_matrix + np.eye(covariance_matrix.shape[0]) * 1e-6\n",
        "inv_covariance_matrix = np.linalg.inv(stabilized_covariance_matrix)\n",
        "variance_vector = np.var(X_train, axis=0)\n",
        "\n",
        "knn_variants = {\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"DistanceKNN\": KNeighborsClassifier(n_neighbors=3, weights='distance'),\n",
        "    \"GeneralizedKNN\": KNeighborsClassifier(n_neighbors=3, metric='minkowski', p=3),\n",
        "    \"EuclideanKNN\": KNeighborsClassifier(n_neighbors=3, metric='euclidean'),\n",
        "    \"ManhattanKNN\": KNeighborsClassifier(n_neighbors=3, metric='manhattan'),\n",
        "    \"ChebyshevKNN\": KNeighborsClassifier(n_neighbors=3, metric='chebyshev'),\n",
        "    \"MahalanobisKNN\": KNeighborsClassifier(n_neighbors=3, metric='mahalanobis', metric_params={'VI': inv_covariance_matrix}),\n",
        "    \"SeuclideanKNN\": KNeighborsClassifier(n_neighbors=3, metric='seuclidean', metric_params={'V': variance_vector}),\n",
        "    \"WminkowskiKNN\": KNeighborsClassifier(n_neighbors=3, metric='minkowski', p=3, metric_params={'w': np.ones(X_train.shape[1])})\n",
        "}\n",
        "\n",
        "# Evaluate all KNN variants\n",
        "for name, model in knn_variants.items():\n",
        "    run_knn_variant(name, model)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Prepare list of (name, estimator) tuples for ensemble\n",
        "estimators = [(name, model) for name, model in knn_variants.items()]\n",
        "\n",
        "# Voting Ensemble\n",
        "voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
        "print(\"\\n==== Voting Ensemble ====\")\n",
        "voting_clf.fit(X_train, y_train)\n",
        "y_pred_voting = voting_clf.predict(X_test)\n",
        "try:\n",
        "    y_prob_voting = voting_clf.predict_proba(X_test)\n",
        "except Exception:\n",
        "    y_prob_voting = None\n",
        "print_metrics(y_test, y_pred_voting, y_prob_voting)\n",
        "\n",
        "# Stacking Ensemble (Logistic Regression as final estimator)\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=KNeighborsClassifier(n_neighbors=3, metric='mahalanobis', metric_params={'VI': inv_covariance_matrix}),\n",
        "    passthrough=False,\n",
        "    cv=5\n",
        ")\n",
        "print(\"\\n==== Stacking Ensemble ====\")\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "y_pred_stacking = stacking_clf.predict(X_test)\n",
        "try:\n",
        "    y_prob_stacking = stacking_clf.predict_proba(X_test)\n",
        "except Exception:\n",
        "    y_prob_stacking = None\n",
        "print_metrics(y_test, y_pred_stacking, y_prob_stacking)\n",
        "\n",
        "print(\"\\nProject complete! Check the above output for performance of each KNN variant and ensemble models.\")"
      ]
    }
  ]
}