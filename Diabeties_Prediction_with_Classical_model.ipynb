{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muajnstu/DSK-Chain-to-predict-diabeties-/blob/main/Diabeties_Prediction_with_Classical_model_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yh9ZHxCtI33u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#from sklearn.metrics import (accuracy_score, confusion_matrix, roc_auc_score, f1_score)\n",
        "from sklearn.metrics import (confusion_matrix, accuracy_score, f1_score, roc_auc_score, recall_score, precision_score)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import neighbors\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    AdaBoostClassifier,\n",
        "    ExtraTreesClassifier,\n",
        "    BaggingClassifier\n",
        ")\n",
        "from sklearn.linear_model import (\n",
        "    LogisticRegression,\n",
        "    RidgeClassifier,\n",
        "    Perceptron,\n",
        "    SGDClassifier,\n",
        "    PassiveAggressiveClassifier\n",
        ")\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import shap\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wKAx8jZjLg3E"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('https://raw.githubusercontent.com/muajnstu/DSK-Chain-to-predict-diabeties-/refs/heads/main/Cleaned%20data%20after%20removal%20of%20duplicate%20values.csv')\n",
        "X = df.drop(columns=['Outcome'])\n",
        "y = df['Outcome']\n",
        "\n",
        "#print(\"Class distribution:\\n\", y.value_counts())\n",
        "# --- Handle Imbalanced Data ---\n",
        "\n",
        "#smote = SMOTE(random_state=42)\n",
        "#X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "#print(\"Balanced class distribution:\\n\", pd.Series(y_resampled).value_counts())\n",
        "# --- Train/Test Split ---\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=46, stratify=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics function\n",
        "def print_metrics(y_true, y_pred, y_prob=None):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    num_classes = cm.shape[0]\n",
        "\n",
        "    if num_classes == 2:\n",
        "        TN, FP, FN, TP = cm.ravel()\n",
        "        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        gmean = np.sqrt(specificity * sensitivity)\n",
        "        type1 = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
        "        type2 = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        fmeasure = f1_score(y_true, y_pred, pos_label=1)\n",
        "        auc = 0\n",
        "        if y_prob is not None and hasattr(y_prob, \"shape\") and y_prob.shape[1] > 1:\n",
        "            try:\n",
        "                auc = roc_auc_score(y_true, y_prob[:, 1])\n",
        "            except Exception:\n",
        "                auc = 0\n",
        "    else:\n",
        "        TP = np.diag(cm)\n",
        "        FP = np.sum(cm, axis=0) - TP\n",
        "        FN = np.sum(cm, axis=1) - TP\n",
        "        TN = np.sum(cm) - (FP + FN + TP)\n",
        "        specificity = np.mean([TN[i] / (TN[i] + FP[i]) if (TN[i] + FP[i]) > 0 else 0 for i in range(num_classes)])\n",
        "        sensitivity = np.mean([TP[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0 for i in range(num_classes)])\n",
        "        gmean = np.sqrt(specificity * sensitivity)\n",
        "        type1 = np.mean([FP[i] / (FP[i] + TN[i]) if (FP[i] + TN[i]) > 0 else 0 for i in range(num_classes)])\n",
        "        type2 = np.mean([FN[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0 for i in range(num_classes)])\n",
        "        fmeasure = f1_score(y_true, y_pred, average='macro')\n",
        "        auc = 0\n",
        "        if y_prob is not None and hasattr(y_prob, \"shape\") and y_prob.shape[1] > 1:\n",
        "            try:\n",
        "                auc = roc_auc_score(y_true, y_prob, multi_class='ovr', average='macro')\n",
        "            except Exception:\n",
        "                auc = 0\n",
        "\n",
        "    print(f\"Accuracy      : {accuracy:.4f}\")\n",
        "    print(f\"Sensitivity   : {sensitivity:.4f}\")\n",
        "    print(f\"Specificity   : {specificity:.4f}\")\n",
        "    print(f\"G-Mean        : {gmean:.4f}\")\n",
        "    print(f\"Type I Error  : {type1:.4f}\")\n",
        "    print(f\"Type II Error : {type2:.4f}\")\n",
        "    print(f\"F1 Score      : {fmeasure:.4f}\")\n",
        "    print(f\"AUROC         : {auc:.4f}\")\n",
        "\n",
        "# Universal runner for any model\n",
        "def run_model(name, model, X_train, X_test, y_train, y_test):\n",
        "    print(f\"\\n===== Running {name} =====\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    try:\n",
        "        y_prob = model.predict_proba(X_test)\n",
        "    except AttributeError:\n",
        "        y_prob = None\n",
        "    print_metrics(y_test, y_pred, y_prob)\n",
        "\n",
        "#  classical ML models\n",
        "ml_models = {\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
        "    \"ExtraTrees\": ExtraTreesClassifier(random_state=42),\n",
        "    \"Bagging\": BaggingClassifier(random_state=42),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"RidgeClassifier\": RidgeClassifier(random_state=42),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"NaiveBayes\": GaussianNB(),\n",
        "    \"Perceptron\": Perceptron(random_state=42),\n",
        "    \"SGDClassifier\": SGDClassifier(random_state=42),\n",
        "    \"PassiveAggressive\": PassiveAggressiveClassifier(random_state=42),\n",
        "    #\"LinearSVM\": SVC(kernel='linear', probability=True, random_state=42),\n",
        "    #\"RBFSVM\": SVC(kernel='rbf', probability=True, random_state=42),\n",
        "    \"LDA\": LinearDiscriminantAnalysis(),\n",
        "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "    \"LightGBM\": LGBMClassifier(verbosity=-1, random_state=42)\n",
        "}\n",
        "\n",
        "\n",
        "# Run all models in a loop\n",
        "for name, model in ml_models.items():\n",
        "    run_model(name, model, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t52CySjO6b4b",
        "outputId": "83039942-79da-41dd-f36b-981cb0c6f2ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Running RandomForest =====\n",
            "Accuracy      : 0.7666\n",
            "Sensitivity   : 0.1220\n",
            "Specificity   : 0.9131\n",
            "G-Mean        : 0.3337\n",
            "Type I Error  : 0.0869\n",
            "Type II Error : 0.8780\n",
            "F1 Score      : 0.1622\n",
            "AUROC         : 0.5786\n",
            "\n",
            "===== Running ExtraTrees =====\n",
            "Accuracy      : 0.7605\n",
            "Sensitivity   : 0.1504\n",
            "Specificity   : 0.8993\n",
            "G-Mean        : 0.3678\n",
            "Type I Error  : 0.1007\n",
            "Type II Error : 0.8496\n",
            "F1 Score      : 0.1888\n",
            "AUROC         : 0.5068\n",
            "\n",
            "===== Running Bagging =====\n",
            "Accuracy      : 0.7440\n",
            "Sensitivity   : 0.1463\n",
            "Specificity   : 0.8799\n",
            "G-Mean        : 0.3588\n",
            "Type I Error  : 0.1201\n",
            "Type II Error : 0.8537\n",
            "F1 Score      : 0.1748\n",
            "AUROC         : 0.5513\n",
            "\n",
            "===== Running GradientBoosting =====\n",
            "Accuracy      : 0.8268\n",
            "Sensitivity   : 0.0772\n",
            "Specificity   : 0.9972\n",
            "G-Mean        : 0.2775\n",
            "Type I Error  : 0.0028\n",
            "Type II Error : 0.9228\n",
            "F1 Score      : 0.1418\n",
            "AUROC         : 0.6883\n",
            "\n",
            "===== Running AdaBoost =====\n",
            "Accuracy      : 0.8148\n",
            "Sensitivity   : 0.0000\n",
            "Specificity   : 1.0000\n",
            "G-Mean        : 0.0000\n",
            "Type I Error  : 0.0000\n",
            "Type II Error : 1.0000\n",
            "F1 Score      : 0.0000\n",
            "AUROC         : 0.6678\n",
            "\n",
            "===== Running LogisticRegression =====\n",
            "Accuracy      : 0.8140\n",
            "Sensitivity   : 0.0000\n",
            "Specificity   : 0.9991\n",
            "G-Mean        : 0.0000\n",
            "Type I Error  : 0.0009\n",
            "Type II Error : 1.0000\n",
            "F1 Score      : 0.0000\n",
            "AUROC         : 0.6141\n",
            "\n",
            "===== Running RidgeClassifier =====\n",
            "Accuracy      : 0.8133\n",
            "Sensitivity   : 0.0000\n",
            "Specificity   : 0.9982\n",
            "G-Mean        : 0.0000\n",
            "Type I Error  : 0.0018\n",
            "Type II Error : 1.0000\n",
            "F1 Score      : 0.0000\n",
            "AUROC         : 0.0000\n",
            "\n",
            "===== Running DecisionTree =====\n",
            "Accuracy      : 0.7026\n",
            "Sensitivity   : 0.1748\n",
            "Specificity   : 0.8226\n",
            "G-Mean        : 0.3792\n",
            "Type I Error  : 0.1774\n",
            "Type II Error : 0.8252\n",
            "F1 Score      : 0.1788\n",
            "AUROC         : 0.4972\n",
            "\n",
            "===== Running NaiveBayes =====\n",
            "Accuracy      : 0.2395\n",
            "Sensitivity   : 0.9228\n",
            "Specificity   : 0.0841\n",
            "G-Mean        : 0.2786\n",
            "Type I Error  : 0.9159\n",
            "Type II Error : 0.0772\n",
            "F1 Score      : 0.3101\n",
            "AUROC         : 0.5809\n",
            "\n",
            "===== Running Perceptron =====\n",
            "Accuracy      : 0.2447\n",
            "Sensitivity   : 0.9390\n",
            "Specificity   : 0.0869\n",
            "G-Mean        : 0.2856\n",
            "Type I Error  : 0.9131\n",
            "Type II Error : 0.0610\n",
            "F1 Score      : 0.3154\n",
            "AUROC         : 0.0000\n",
            "\n",
            "===== Running SGDClassifier =====\n",
            "Accuracy      : 0.6604\n",
            "Sensitivity   : 0.4675\n",
            "Specificity   : 0.7043\n",
            "G-Mean        : 0.5738\n",
            "Type I Error  : 0.2957\n",
            "Type II Error : 0.5325\n",
            "F1 Score      : 0.3377\n",
            "AUROC         : 0.0000\n",
            "\n",
            "===== Running PassiveAggressive =====\n",
            "Accuracy      : 0.8163\n",
            "Sensitivity   : 0.0244\n",
            "Specificity   : 0.9963\n",
            "G-Mean        : 0.1559\n",
            "Type I Error  : 0.0037\n",
            "Type II Error : 0.9756\n",
            "F1 Score      : 0.0469\n",
            "AUROC         : 0.0000\n",
            "\n",
            "===== Running LDA =====\n",
            "Accuracy      : 0.8125\n",
            "Sensitivity   : 0.0041\n",
            "Specificity   : 0.9963\n",
            "G-Mean        : 0.0636\n",
            "Type I Error  : 0.0037\n",
            "Type II Error : 0.9959\n",
            "F1 Score      : 0.0080\n",
            "AUROC         : 0.5899\n",
            "\n",
            "===== Running QDA =====\n",
            "Accuracy      : 0.2741\n",
            "Sensitivity   : 0.8902\n",
            "Specificity   : 0.1340\n",
            "G-Mean        : 0.3454\n",
            "Type I Error  : 0.8660\n",
            "Type II Error : 0.1098\n",
            "F1 Score      : 0.3124\n",
            "AUROC         : 0.5874\n",
            "\n",
            "===== Running XGBoost =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [19:39:18] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy      : 0.8163\n",
            "Sensitivity   : 0.1382\n",
            "Specificity   : 0.9704\n",
            "G-Mean        : 0.3662\n",
            "Type I Error  : 0.0296\n",
            "Type II Error : 0.8618\n",
            "F1 Score      : 0.2179\n",
            "AUROC         : 0.6875\n",
            "\n",
            "===== Running LightGBM =====\n",
            "Accuracy      : 0.8200\n",
            "Sensitivity   : 0.1220\n",
            "Specificity   : 0.9787\n",
            "G-Mean        : 0.3455\n",
            "Type I Error  : 0.0213\n",
            "Type II Error : 0.8780\n",
            "F1 Score      : 0.2007\n",
            "AUROC         : 0.6872\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
